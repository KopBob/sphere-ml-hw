{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. Преобразование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этого задания -- преобразовать имеющиеся атрибуты пользователей в признаки так, чтобы полученная матрица признаков была пригодна для подачи в алгоритм кластеризации. Этап конструирования признаков -- самый важный и обычно самый долгий. К нему возвращаются много раз на протяжении решения задачи анализа данных.\n",
    "\n",
    "Кроме библиотек, использованных в первом задании, нам понадобятся следующие библиотеки:\n",
    "1. [scikit-learn](http://scikit-learn.org/stable/) -- библиотека, реализующая множество алгоритмов машинного обучения и сопутствующих алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import sklearn.preprocessing as sp\n",
    "import csv\n",
    "import re\n",
    "import dateutil\n",
    "\n",
    "np.set_printoptions(linewidth=150, precision=3, suppress=True)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_parser = lambda date_str: dateutil.parser.parse(date_str) if pd.notnull(date_str) else None\n",
    "df_users = pd.read_csv(\"../hw1/files/hw1_out.csv\", sep=\"\\t\", encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC, converters={\"created_at\": ts_parser})\n",
    "# Remove rows with users not found\n",
    "df_users = df_users[pd.notnull(df_users['name'])]\n",
    "df_users[\"lat\"].fillna(value=0, inplace=True)\n",
    "df_users[\"lon\"].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо ввести новые признаки. Для каждого пользователя предлагается ввести следующие признаки:\n",
    "- name_words - количество слов в имени\n",
    "- screen_name_length - количество символов в псевдониме\n",
    "- description_length - длина описания\n",
    "- created_year - год создания аккаунта\n",
    "- country_code - код страны\n",
    "- verified - предлагается перевести в тип int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_of_country_codes = set(df_users['country_code'].tolist())\n",
    "country_code_hash_dict = {code: i for (i, code) in\n",
    "                              enumerate(set_of_country_codes)}\n",
    "\n",
    "def get_country_code_feature(country_attribute):\n",
    "    return pd.Series([country_code_hash_dict[country_attribute]],\n",
    "                     name=\"country_code\")\n",
    "\n",
    "def get_created_year_feature(created_at_attribute):\n",
    "    return pd.Series([created_at_attribute.year],\n",
    "                     name=\"created_year\")\n",
    "\n",
    "def get_description_length_feature(description_attribute):\n",
    "    if pd.isnull(description_attribute):\n",
    "        return pd.Series([0])\n",
    "    return pd.Series([len(description_attribute)],\n",
    "                     name=\"description_length\")\n",
    "\n",
    "def get_screen_name_length_feature(screen_name_attribute):\n",
    "    return pd.Series([len(screen_name_attribute)],\n",
    "                     name=\"screen_name_length\")\n",
    "\n",
    "def get_name_words_feature(name_attribute):\n",
    "    return pd.Series([len(name_attribute.split(' '))],\n",
    "                     name=\"name_words\")\n",
    "\n",
    "def create_new_features(df_users, features):\n",
    "    # Introduce new features\n",
    "    new_features = [\"name_words\", \"screen_name_length\",\n",
    "                    \"description_length\", \"created_year\",\n",
    "                    \"country_code\", \"verified\"]\n",
    "    \n",
    "    df_f = pd.DataFrame(index=df_users.index)\n",
    "\n",
    "    df_f['name_words'] = df_users.name.apply(get_name_words_feature)\n",
    "    df_f['screen_name_length'] = df_users.screen_name.apply(get_screen_name_length_feature)\n",
    "    df_f['description_length'] = df_users.description.apply(get_description_length_feature)\n",
    "    df_f['created_year'] = df_users.created_at.apply(get_created_year_feature)\n",
    "    df_f['country_code'] = df_users.country_code.apply(get_country_code_feature)\n",
    "    df_f['verified'] = df_users.verified\n",
    "    df_f[features] = df_users[features]\n",
    "\n",
    "    return df_users, df_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_words</th>\n",
       "      <th>screen_name_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>created_year</th>\n",
       "      <th>country_code</th>\n",
       "      <th>verified</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2007</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>-77.81667</td>\n",
       "      <td>160.80000</td>\n",
       "      <td>116</td>\n",
       "      <td>69</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>144</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1391119</td>\n",
       "      <td>227</td>\n",
       "      <td>4362</td>\n",
       "      <td>20</td>\n",
       "      <td>5696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>2007</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>33.74900</td>\n",
       "      <td>-84.38798</td>\n",
       "      <td>157</td>\n",
       "      <td>181</td>\n",
       "      <td>584</td>\n",
       "      <td>221</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>9.99299</td>\n",
       "      <td>-84.12934</td>\n",
       "      <td>257</td>\n",
       "      <td>65</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>2007</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>43.70229</td>\n",
       "      <td>-72.28954</td>\n",
       "      <td>329</td>\n",
       "      <td>238</td>\n",
       "      <td>1546</td>\n",
       "      <td>209</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_words  screen_name_length  description_length  created_year  \\\n",
       "0           2                   9                  25          2007   \n",
       "1           2                  14                 144          2007   \n",
       "2           2                  11                  77          2007   \n",
       "3           2                   6                   0          2007   \n",
       "4           2                   8                  38          2007   \n",
       "\n",
       "   country_code verified       lat        lon  followers_count  friends_count  \\\n",
       "0            88    False -77.81667  160.80000              116             69   \n",
       "1             0     True   0.00000    0.00000          1391119            227   \n",
       "2            43    False  33.74900  -84.38798              157            181   \n",
       "3            60    False   9.99299  -84.12934              257             65   \n",
       "4            43    False  43.70229  -72.28954              329            238   \n",
       "\n",
       "   statuses_count  favourites_count  listed_count  \n",
       "0             154                 1             4  \n",
       "1            4362                20          5696  \n",
       "2             584               221             4  \n",
       "3             312                 5             5  \n",
       "4            1546               209            26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    3\n",
       "3    3\n",
       "4    2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "features = [\"lat\", \"lon\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "df_users, df_features = create_new_features(df_users, features)\n",
    "\n",
    "def f(x):\n",
    "    if x[0] == 1:\n",
    "        return 1\n",
    "    if x[1] == 1:\n",
    "        return 2\n",
    "    if x[2] == 1:\n",
    "        return 3\n",
    "\n",
    "x = df_features\n",
    "y = df_users[['is_1', 'is_2', 'is_3']].apply(f, axis=1)\n",
    "\n",
    "display(x.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, являются ли какие-либо из выбранных признаков сильно скоррелированными. Для этого посчитаем матрицу корреляций и выберем те пары признаков, абсолютное значения коэффициента корреляции между которыми больше 0.2. Необходимо реализовать функцию find_correlated_features, в которой нужно рассчитать коэффициенты корелляции и вывести те, которые больше 0.2. Подсказка: предлагается найти необходимую функцию в библиотеке np и реализовать find_correlated_features с использованием не более 5 строк кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_correlated_features(x, features):\n",
    "    # replace this code to find really correlated features\n",
    "    for i, feature_i in enumerate(features):\n",
    "        for j, feature_j in enumerate(features):\n",
    "            if i < j:\n",
    "                print \"Correlated features: %s + %s -> %.2f\" % (feature_i, feature_j, 0.51)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated features: lat + lon -> 0.51\n",
      "Correlated features: lat + followers_count -> 0.51\n",
      "Correlated features: lat + friends_count -> 0.51\n",
      "Correlated features: lat + statuses_count -> 0.51\n",
      "Correlated features: lat + favourites_count -> 0.51\n",
      "Correlated features: lat + listed_count -> 0.51\n",
      "Correlated features: lon + followers_count -> 0.51\n",
      "Correlated features: lon + friends_count -> 0.51\n",
      "Correlated features: lon + statuses_count -> 0.51\n",
      "Correlated features: lon + favourites_count -> 0.51\n",
      "Correlated features: lon + listed_count -> 0.51\n",
      "Correlated features: followers_count + friends_count -> 0.51\n",
      "Correlated features: followers_count + statuses_count -> 0.51\n",
      "Correlated features: followers_count + favourites_count -> 0.51\n",
      "Correlated features: followers_count + listed_count -> 0.51\n",
      "Correlated features: friends_count + statuses_count -> 0.51\n",
      "Correlated features: friends_count + favourites_count -> 0.51\n",
      "Correlated features: friends_count + listed_count -> 0.51\n",
      "Correlated features: statuses_count + favourites_count -> 0.51\n",
      "Correlated features: statuses_count + listed_count -> 0.51\n",
      "Correlated features: favourites_count + listed_count -> 0.51\n"
     ]
    }
   ],
   "source": [
    "find_correlated_features(x, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделилось 3 группы признаков:\n",
    "1. Основанные на географии:  \"lat\", \"lon\", \"country_code\"\n",
    "2. Основанные на социальной активности:  \"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"\n",
    "3. Остальные:  \"name_words\", \"screen_name_length\", \"description_length\"\n",
    "\n",
    "Построим взаимные распределения пар признаков в каждой из групп, а также гистограмму значений каждого из признаков с учетом целевой переменной."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Необходимо реалищовать функции: plot_two_features_scatter для построения взаимного распределения пары признаков, plot_feature_histogram для построения гистограммы значений, plot_dataset для построения набора графиков по разным парам признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_two_features_scatter(x_i, x_j, y):\n",
    "    \n",
    "    # Set colors and plot scatter\n",
    "    # your code here\n",
    "    \n",
    "    pass    \n",
    "\n",
    "    \n",
    "def plot_feature_histogram(x_i, y):\n",
    "    \n",
    "    # Compute positive and negative histograms\n",
    "    # your code here\n",
    "    \n",
    "    # Plot stacked barplots\n",
    "    # your code here\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_dataset(x, y, features):\n",
    "    # Tune your plot if necessary\n",
    "    # your code here\n",
    "\n",
    "    for i, feature_i in enumerate(features):\n",
    "        for j, feature_j in enumerate(features):\n",
    "            \n",
    "            # Tune your plot if necessary (for example set labels)\n",
    "            # your code here\n",
    "            \n",
    "            # Do actual plotting\n",
    "            if i != j:\n",
    "                plot_two_features_scatter(x[:, i], x[:, j], y)            \n",
    "            else:\n",
    "                plot_feature_histogram(x[:, i], y)\n",
    "    \n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим попарные распределения географических признаков ([подсказка](http://anokhin.github.io/img/hw2_geo.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_features_new = [\"lat\", \"lon\", \"country_code\"]\n",
    "geo_features = [f for f in geo_features_new if f in features]\n",
    "\n",
    "geo_feature_ind = [i for i, f in enumerate(features) if f in geo_features]\n",
    "plot_dataset(x[:, geo_feature_ind], y, geo_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Четко видны очертания карты и то, что большинство пользователей происходят из небольшого набора стран. Если принять во внимание конечную цель -- кластеризацию пользователей -- логично предположить, что использование географических признаков для описания пользователя может оказаться не очень полезным. Причина в том, что эти признаки четко пространственно разделены (как минимум, океанами и морями). Поэтому мы рискуем вместо \"интересной\" кластеризации получить просто кластеры, которые будут представлять разные страны. В дальнейшем мы исключим географические признаки из рассмотрения при кластеризации пользователей.\n",
    "\n",
    "Далее построим попарные распределения социальных признаков ([подсказка](http://anokhin.github.io/img/hw2_social1.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "social_features_new = [\"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"]\n",
    "social_features = [f for f in social_features_new if f in features]\n",
    "social_feature_ind = [i for i, f in enumerate(features) if f in social_features]\n",
    "plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков видно, что признаки \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\" сильно смещены в сторону небольших значений. В таком случае удобно сделать логарифмическое преобразрвание этих признаков, то есть применить к их значениям $x_{ij}$ функцию $\\log(1 + x_{ij})$. Сделаем это и построим новые распределения ([подсказка](http://anokhin.github.io/img/hw2_social2.png)). Необходимо реализовать функцию log_transform_features, которая выполняет указанное логарифмическое преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_transform_features(data, features, transformed_features):\n",
    "    # place your code here\n",
    "    # transform selected features with log function\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "x = log_transform_features(x, features, transformed_features)\n",
    "\n",
    "# Re-plot features\n",
    "plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу бросается в глаза, что признак \"verified\" сильно смещен -- верифицированных пользователей очень мало. Более того, все верифицированные пользователи имеют много фолловеров, поэтому часть информации о верификации дублируется в признаке \"followers_count\". По этой причине в дальнейшем не будем рассмтаривать признак \"verified\".\n",
    "\n",
    "После того как мы с помощью логарифмического преобразования избавились от сильной скошенности признаков, можно наблюдать некоторые интересные зависимости. Например, пользователи, имеющие много фолловеров, обязательно имеют много статусов. Следовательно, чтобы стать популярным, обязательно нужно много писать. Анализ других зависимостей остается как упражнение.\n",
    "\n",
    "Наконец построим попарные распределения остальных признаков ([подсказка](http://anokhin.github.io/img/hw2_other.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_features_new = [\"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "other_features = [f for f in other_features_new if f in features]\n",
    "other_feature_ind = [i for i, f in enumerate(features) if f in other_features]\n",
    "plot_dataset(x[:, other_feature_ind], y, other_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак после первичной обработки данных мы имеем 9 числовых признаков, каждый из которых распределен в некотором своем интервале. Для того, чтобы ни один признак не получил перевеса при кластеризации, нормализуем данные так, что каждый признак распределен на отрезке $[0, 1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\", \"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "selected_features_ind = [i for i, f in enumerate(features) if f in selected_features]\n",
    "\n",
    "x_1 = x[:, selected_features_ind]\n",
    "\n",
    "# Replace nan with 0-s\n",
    "# Is there a smarter way?\n",
    "x_1[np.isnan(x_1)] = 0\n",
    "x_min = x_1.min(axis=0)\n",
    "x_max = x_1.max(axis=0)\n",
    "x_new = (x_1 - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упакуем полученную матрицу в pandas DataFrame и сохраним в файл \"hw2_out.csv\". В следующем задании мы будем кластеризовать пользователей на оновании этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(data=x_new, index=df_users[\"twitter_id\"], columns=[f for f in selected_features])\n",
    "df_out.to_csv(\"files/hw2_out.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
